{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 950 (CNMeM is enabled with initial size: 66.0% of memory, cuDNN 5105)\n",
      "/usr/local/lib/python2.7/dist-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import collections\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4531\n",
      "27629896\n"
     ]
    }
   ],
   "source": [
    "def remove_hidden(l):\n",
    "    return filter(lambda s: not s[0] == '.', l)\n",
    "\n",
    "d = \"//home//xgamer//OANC-GrAF//data//written_1//journal//slate\"\n",
    "\n",
    "def get_files(d):\n",
    "    files = os.listdir(d)\n",
    "    files = remove_hidden(files)\n",
    "    return map(lambda f: d + \"//\" + f, files)\n",
    "\n",
    "dirs = get_files(d)\n",
    "files = map(get_files, dirs)\n",
    "files = [f for l in files for f in l]\n",
    "files = filter(lambda f: f[-3:] == 'txt', files)\n",
    "\n",
    "print len(files)\n",
    "\n",
    "texts = []\n",
    "for f in files:\n",
    "    f = open(f)\n",
    "    texts.append('\\n'.join(f.readlines()[7:]))\n",
    "    f.close()\n",
    "\n",
    "print sum([len(text) for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25425786\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = text.strip()\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('--', ' - ')\n",
    "    text = text.replace('\\t', ' ')\n",
    "    text = re.sub(r'\\ \\ +', r' ', text)\n",
    "    text = filter(lambda char: char in string.printable, text)\n",
    "    return text\n",
    "\n",
    "texts = map(clean_text, texts)\n",
    "print sum([len(text) for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trustbusters Have Job Security The Dec. 14 edition of \"Today's Papers\" notes a Washington Post report that David Boies, the lead Justice Department attorney in the Microsoft case, has lowered the hourly fee that he is charging the government. The column asks whether this is legal, if Boies' motive was to keep his share of the work. The answer can be found in the definitive rhyming opus on antitrust law, R.W. Grant's Tom Smith and His Incredible Bread Machine : You're gouging on your prices if You charge more than the rest. But it's unfair competition If you think you can charge less! A second point that we would make To help avoid confusion Don't try to charge the same amount! That would be collusion! In short, Boies' reduction of his fee constitutes unfair competition. Of course, if he'd left his fee unchanged, that would be collusion, though in this case he'd be colluding with himself and would eventually go blind. How's that for legal clarity? - Sam Kazman Washington Bork and Mindy Are there two Robert Borks, as Michael Kinsley writes in \"\"? But not just on antitrust. We have two Borks for probably any subject. Give the man a retainer or the proper ideological cause and he readily will tailor his views to the needs of the moment. I interviewed Bork several years ago for my book The Wars of Watergate . His role in the Watergate affair has, in all fairness, been badly distorted. Never mind. In our conversation, he spoke very forcefully against the special prosecutor (now independent counsel) statute. \"You cannot bag a case in the Justice Department,\" he told me. \"Too many lawyers, who like to talk to too many reporters.\" He was absolutely right, of course. Fast forward to 1994 and beyond. An independent counsel to investigate President Clinton? Of course. And \"Judge\" Kenneth Starr to conduct the investigation? Of course, said Bork, who appears as a regular cast member in those situation comedies that pass as \"talk shows\" every night, vigorously extolling the virtues and honesty of \"Judge\" Starr. Kinsley comes close to the real reason for rejecting Bork for a seat on the Supreme Court. The man has the intellectual honesty of a hired gun. Which he has truly become. - Stanley I. Kutler Fox Professor of American Institutions University of Wisconsin Madison, Wis. First, We Kill All the Lawyers I'm sure Michael Kinsley's \"Book Bork, Browser Bork\" is right to say that Robert Bork's current posture on the Microsoft antitrust case represents a departure from his 20-year-old book on antitrust law. But since when is a lawyer expected to actually possess the views he espouses on behalf of his clients? If the Kinsley Doctrine is that a client can only select a lawyer who honestly believes in the legal arguments of the client, then Bill Clinton wouldn't have any lawyers. - Robert Little Memphis, Tenn. Perjury Is Bad, Smearing Is Worse Just a quick point on David Plotz's \"Dispatch \" from the Dec. 9 House Judiciary Committee hearing. Plotz writes, \"Yesterday I called Lindsey Graham, R-S.C., 'admirable.' I apologize. ... This afternoon, Graham reveals himself, and he does it in such a calculating way that I wonder whether everything he has done till now has been pure performance. As the final speaker on the final day of hearings, Graham unleashes a 15 minute harangue about Clintonian evil. Clinton's true crime is not perjury or adultery, Graham shouts, it's that he planned to destroy Monica.\" Isn't the most reprehensible aspect of Clinton's conduct from a moral point of view the fact that he either orchestrated or knowingly permitted the resources of his position and office to be used in an attempt to destroy the reputations of those who have accused him of misdeeds? The story of the sexual activity is disturbing, given the power imbalances between the participants, but the story is a tawdry one, and most well-mannered people would just as soon not have to hear about it, especially since the \"victim\" is not making any complaint. The lying can be viewed as a natural human failing, which most people, it appears, are ready to forgive. Lying under oath is a more serious matter, but it is more serious for institutional reasons rather than purely moral ones. As the head of state and a living symbol of a system, which, in the name of justice, imposes laws upon and claims the right to exercise coercive power over all Americans, the president has a special duty - higher than that of an ordinary citizen - to abide by the rules that the system imposes. One of the most important rules for the whole justice system is the penalty against perjury. It is only right that Congress should take that issue seriously. But from a purely moral point of view, is it not utterly despicable for the president of the United States to use the power of his office to destroy the reputation of a person for the sole purpose of ensuring that that person will not be believed when she tells the truth? Such conduct may not be a \"high crime or misdemeanor.\" It may not even be illegal. But it is surely a moral abuse of the powers of the presidency that should not go unnoticed. - Kenneth J. Tyler Vancouver, British Columbia Jocks of the World, Unite! You Have Nothing To Lose but Your Scholarships! Jim Naughton's \"\" has missed the forest for the trees. He complains that a few powerful schools are aligning themselves to take a larger slice of the revenues generated by big-time college athletics and bemoans the small colleges whose athletic programs will be destroyed by this. What Naughton has missed is that the entire NCAA system is corrupt, making millions of dollars off student athletes who can't even accept plane fare from alumni to visit family. That's the real travesty of college sports. Arguing which schools should keep the huge revenues generated by athletes really misses the point. - Anthony Lapadula Redmond, Wash. Address your e-mail to the editors to letters@slate.com. You must include your address and daytime phone number (for confirmation only).\n"
     ]
    }
   ],
   "source": [
    "print texts[545]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '}', '~', '\\t', '\\n']\n",
      "{0: ' ', 1: '!', 2: '\"', 3: '#', 4: '$', 5: '%', 6: '&', 7: \"'\", 8: '(', 9: ')', 10: '*', 11: '+', 12: ',', 13: '-', 14: '.', 15: '/', 16: '0', 17: '1', 18: '2', 19: '3', 20: '4', 21: '5', 22: '6', 23: '7', 24: '8', 25: '9', 26: ':', 27: ';', 28: '<', 29: '=', 30: '>', 31: '?', 32: '@', 33: 'A', 34: 'B', 35: 'C', 36: 'D', 37: 'E', 38: 'F', 39: 'G', 40: 'H', 41: 'I', 42: 'J', 43: 'K', 44: 'L', 45: 'M', 46: 'N', 47: 'O', 48: 'P', 49: 'Q', 50: 'R', 51: 'S', 52: 'T', 53: 'U', 54: 'V', 55: 'W', 56: 'X', 57: 'Y', 58: 'Z', 59: '[', 60: '\\\\', 61: ']', 62: '^', 63: '_', 64: '`', 65: 'a', 66: 'b', 67: 'c', 68: 'd', 69: 'e', 70: 'f', 71: 'g', 72: 'h', 73: 'i', 74: 'j', 75: 'k', 76: 'l', 77: 'm', 78: 'n', 79: 'o', 80: 'p', 81: 'q', 82: 'r', 83: 's', 84: 't', 85: 'u', 86: 'v', 87: 'w', 88: 'x', 89: 'y', 90: 'z', 91: '{', 92: '}', 93: '~', 94: '\\t', 95: '\\n'}\n",
      "{' ': 0, '$': 4, '(': 8, ',': 12, '0': 16, '4': 20, '8': 24, '<': 28, '@': 32, 'D': 36, 'H': 40, 'L': 44, 'P': 48, 'T': 52, 'X': 56, '\\\\': 60, '`': 64, 'd': 68, 'h': 72, 'l': 76, 'p': 80, 't': 84, 'x': 88, '#': 3, \"'\": 7, '+': 11, '/': 15, '3': 19, '7': 23, ';': 27, '?': 31, 'C': 35, 'G': 39, 'K': 43, 'O': 47, 'S': 51, 'W': 55, '[': 59, '_': 63, 'c': 67, 'g': 71, 'k': 75, 'o': 79, 's': 83, 'w': 87, '{': 91, '\\n': 95, '\"': 2, '&': 6, '*': 10, '.': 14, '2': 18, '6': 22, ':': 26, '>': 30, 'B': 34, 'F': 38, 'J': 42, 'N': 46, 'R': 50, 'V': 54, 'Z': 58, '^': 62, 'b': 66, 'f': 70, 'j': 74, 'n': 78, 'r': 82, 'v': 86, 'z': 90, '~': 93, '\\t': 94, '!': 1, '%': 5, ')': 9, '-': 13, '1': 17, '5': 21, '9': 25, '=': 29, 'A': 33, 'E': 37, 'I': 41, 'M': 45, 'Q': 49, 'U': 53, 'Y': 57, ']': 61, 'a': 65, 'e': 69, 'i': 73, 'm': 77, 'q': 81, 'u': 85, 'y': 89, '}': 92}\n"
     ]
    }
   ],
   "source": [
    "alphabet = collections.defaultdict(bool)\n",
    "\n",
    "for text in texts:\n",
    "    for char in text:\n",
    "        alphabet[char] = True\n",
    "\n",
    "alphabet = [char for char in alphabet if alphabet[char] == True]\n",
    "alphabet.sort()\n",
    "\n",
    "# Add a start of sequence token \\t\n",
    "alphabet.append('\\t')\n",
    "# Add an end of sequence token \\n\n",
    "alphabet.append('\\n')\n",
    "\n",
    "texts = map(lambda text: '\\t' + text + '\\n', texts)\n",
    "print alphabet\n",
    "\n",
    "char_to_index = {}\n",
    "index_to_char = {}\n",
    "for i in xrange(len(alphabet)):\n",
    "    index_to_char[i] = alphabet[i]\n",
    "    char_to_index[alphabet[i]] = i\n",
    "print index_to_char\n",
    "print char_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " quotidian proximity that the role affords, has demonstrated a proven knack for understated aptness in its selections. Ronald \"Rawhide\" Reagan. Dan \"Scorecard\" Quayle. Edward \"Sunburn\" Kennedy. Jimmy \"\n",
      "[ 0 81 85 79 84 73 68 73 65 78  0 80 82 79 88 73 77 73 84 89  0 84 72 65 84\n",
      "  0 84 72 69  0 82 79 76 69  0 65 70 70 79 82 68 83 12  0 72 65 83  0 68 69\n",
      " 77 79 78 83 84 82 65 84 69 68  0 65  0 80 82 79 86 69 78  0 75 78 65 67 75\n",
      "  0 70 79 82  0 85 78 68 69 82 83 84 65 84 69 68  0 65 80 84 78 69 83 83  0\n",
      " 73 78  0 73 84 83  0 83 69 76 69 67 84 73 79 78 83 14  0 50 79 78 65 76 68\n",
      "  0  2 50 65 87 72 73 68 69  2  0 50 69 65 71 65 78 14  0 36 65 78  0  2 51\n",
      " 67 79 82 69 67 65 82 68  2  0 49 85 65 89 76 69 14  0 37 68 87 65 82 68  0\n",
      "  2 51 85 78 66 85 82 78  2  0 43 69 78 78 69 68 89 14  0 42 73 77 77 89  0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "200 200\n"
     ]
    }
   ],
   "source": [
    "text_seq = ''.join(texts)\n",
    "sample_len = 200\n",
    "\n",
    "def sample(text, length=sample_len + 1):\n",
    "    i = random.randint(0, len(text) - length - 1)\n",
    "    return text[i:i+length]\n",
    "\n",
    "def toseqs(string, alphabet=alphabet):\n",
    "    assert len(string) > 1\n",
    "    n = len(string) - 1\n",
    "    data = np.zeros(n, dtype='int')\n",
    "    label = np.zeros(len(alphabet), dtype='uint8')\n",
    "    for i in xrange(n):\n",
    "        cur = string[i]\n",
    "        data[i] = char_to_index[cur]\n",
    "    nxt = string[i+1]\n",
    "    label[char_to_index[nxt]] = 1\n",
    "    return data, label\n",
    "\n",
    "s = sample(text_seq)\n",
    "print s\n",
    "x,y = toseqs(s)\n",
    "print x\n",
    "print y\n",
    "\n",
    "def tostring(seq, alphabet=alphabet):\n",
    "    string = []\n",
    "    for i in xrange(seq.shape[0]):\n",
    "        string.append(index_to_char[np.argmax(seq[i])])\n",
    "    return ''.join(string)\n",
    "\n",
    "print len(x), len(tostring(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "NN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 96\n"
     ]
    }
   ],
   "source": [
    "embedding_size = len(alphabet)\n",
    "n_lstm_cells = 1000\n",
    "dropout_perc = 0.1\n",
    "\n",
    "model = Sequential()\n",
    "print sample_len, len(alphabet)\n",
    "model.add(Embedding(len(alphabet), embedding_size, input_length=sample_len))\n",
    "model.add(LSTM(n_lstm_cells))\n",
    "model.add(Dropout(dropout_perc))\n",
    "model.add(Dense(len(alphabet)))\n",
    "model.add(Activation('softmax'))\n",
    "#opt = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "opt = RMSprop()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_batches_per_epoch = 5001\n",
    "\n",
    "def get_batch(size, text=text_seq):\n",
    "    xs = np.zeros((size, sample_len), dtype='int')\n",
    "    ys = np.zeros((size, len(alphabet)), dtype='uint8')\n",
    "    for i in xrange(size):\n",
    "        s = sample(text)\n",
    "        xs[i],ys[i] = toseqs(s)\n",
    "    return xs, ys\n",
    "\n",
    "valid_x, valid_y = get_batch(batch_size)\n",
    "seen_samples = 0\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.models.Sequential object at 0x7f5d3ca12290>\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"charlevel_b2.h5\")\n",
    "print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saw 966656 samples.\n",
      "Ran 13008.488054 seconds. (This epoch: 92.8076977699 samples / second)\n",
      "Train accuracy: 0.5465625\n",
      "Test accuracy: 0.65625\n",
      "\n",
      "Saw 973056 samples.\n",
      "Ran 13077.0131671 seconds. (This epoch: 93.0996619954 samples / second)\n",
      "Train accuracy: 0.5490625\n",
      "Test accuracy: 0.65625\n",
      "\n",
      "Saw 979456 samples.\n",
      "Ran 13145.4120572 seconds. (This epoch: 93.2549891513 samples / second)\n",
      "Train accuracy: 0.54390625\n",
      "Test accuracy: 0.671875\n",
      "\n",
      "Saw 985856 samples.\n",
      "Ran 13213.615478 seconds. (This epoch: 93.3994362926 samples / second)\n",
      "Train accuracy: 0.54953125\n",
      "Test accuracy: 0.6875\n",
      "\n",
      "Saw 992256 samples.\n",
      "Ran 13284.828984 seconds. (This epoch: 92.6731116033 samples / second)\n",
      "Train accuracy: 0.53140625\n",
      "Test accuracy: 0.625\n",
      "\n",
      "Saw 998656 samples.\n",
      "Ran 13356.686486 seconds. (This epoch: 92.0526505548 samples / second)\n",
      "Train accuracy: 0.5534375\n",
      "Test accuracy: 0.671875\n",
      "\n",
      "Saw 1005056 samples.\n",
      "Ran 13426.2055511 seconds. (This epoch: 92.0538525027 samples / second)\n",
      "Train accuracy: 0.54484375\n",
      "Test accuracy: 0.703125\n",
      "\n",
      "Saw 1011456 samples.\n",
      "Ran 13496.5790861 seconds. (This epoch: 91.9137245872 samples / second)\n",
      "Train accuracy: 0.555\n",
      "Test accuracy: 0.65625\n",
      "\n",
      "Saw 1017856 samples.\n",
      "Ran 13568.7585371 seconds. (This epoch: 91.5418008121 samples / second)\n",
      "Train accuracy: 0.5465625\n",
      "Test accuracy: 0.65625\n",
      "\n",
      "Saw 1024256 samples.\n",
      "Ran 13638.154494 seconds. (This epoch: 91.6095371987 samples / second)\n",
      "Train accuracy: 0.54328125\n",
      "Test accuracy: 0.625\n",
      "\n",
      "Saw 1030656 samples.\n",
      "Ran 13707.0137801 seconds. (This epoch: 91.7290837302 samples / second)\n",
      "Train accuracy: 0.5509375\n",
      "Test accuracy: 0.65625\n",
      "\n",
      "Saw 1037056 samples.\n",
      "Ran 13777.5376072 seconds. (This epoch: 91.6467108609 samples / second)\n",
      "Train accuracy: 0.54859375\n",
      "Test accuracy: 0.65625\n",
      "\n",
      "Saw 1043456 samples.\n",
      "Ran 13845.4080572 seconds. (This epoch: 91.8451473969 samples / second)\n",
      "Train accuracy: 0.55359375\n",
      "Test accuracy: 0.640625\n",
      "\n",
      "Saw 1049856 samples.\n",
      "Ran 13913.33462 seconds. (This epoch: 92.0106430328 samples / second)\n",
      "Train accuracy: 0.55296875\n",
      "Test accuracy: 0.671875\n",
      "\n",
      "Saw 1056256 samples.\n",
      "Ran 13981.3581691 seconds. (This epoch: 92.1459973417 samples / second)\n",
      "Train accuracy: 0.5475\n",
      "Test accuracy: 0.65625\n",
      "\n",
      "Saw 1062656 samples.\n",
      "Ran 14050.2526932 seconds. (This epoch: 92.1924655022 samples / second)\n",
      "Train accuracy: 0.5490625\n",
      "Test accuracy: 0.640625\n",
      "\n",
      "Saw 1069056 samples.\n",
      "Ran 14118.475142 seconds. (This epoch: 92.2860572499 samples / second)\n",
      "Train accuracy: 0.555625\n",
      "Test accuracy: 0.625\n",
      "\n",
      "Saw 1075456 samples.\n",
      "Ran 14188.821748 seconds. (This epoch: 92.212447526 samples / second)\n",
      "Train accuracy: 0.53234375\n",
      "Test accuracy: 0.65625\n",
      "\n",
      "Saw 1081856 samples.\n",
      "Ran 14259.252728 seconds. (This epoch: 92.1407934542 samples / second)\n",
      "Train accuracy: 0.5525\n",
      "Test accuracy: 0.6875\n",
      "\n",
      "Saw 1088256 samples.\n",
      "Ran 14329.0528312 seconds. (This epoch: 92.1181804702 samples / second)\n",
      "Train accuracy: 0.54859375\n",
      "Test accuracy: 0.640625\n",
      "\n",
      "Saw 1094656 samples.\n",
      "Ran 14398.746129 seconds. (This epoch: 92.1044674161 samples / second)\n",
      "Train accuracy: 0.55125\n",
      "Test accuracy: 0.703125\n",
      "\n",
      "Saw 1101056 samples.\n",
      "Ran 14467.663532 seconds. (This epoch: 92.1387416508 samples / second)\n",
      "Train accuracy: 0.54515625\n",
      "Test accuracy: 0.6875\n",
      "\n",
      "Saw 1107456 samples.\n",
      "Ran 14536.0425611 seconds. (This epoch: 92.2011271166 samples / second)\n",
      "Train accuracy: 0.55796875\n",
      "Test accuracy: 0.640625\n",
      "\n",
      "Saw 1113856 samples.\n",
      "Ran 14605.5378101 seconds. (This epoch: 92.1966030307 samples / second)\n",
      "Train accuracy: 0.5509375\n",
      "Test accuracy: 0.625\n",
      "\n",
      "Saw 1120256 samples.\n",
      "Ran 14673.839442 seconds. (This epoch: 92.255866148 samples / second)\n",
      "Train accuracy: 0.55265625\n",
      "Test accuracy: 0.640625\n",
      "\n",
      "Saw 1126656 samples.\n",
      "Ran 14745.7663071 seconds. (This epoch: 92.1254374396 samples / second)\n",
      "Train accuracy: 0.545\n",
      "Test accuracy: 0.640625\n",
      "\n",
      "Saw 1133056 samples.\n",
      "Ran 14815.3085072 seconds. (This epoch: 92.1219172106 samples / second)\n",
      "Train accuracy: 0.54953125\n",
      "Test accuracy: 0.59375\n",
      "\n",
      "Saw 1139456 samples.\n",
      "Ran 14884.739326 seconds. (This epoch: 92.1239213514 samples / second)\n",
      "Train accuracy: 0.55\n",
      "Test accuracy: 0.65625\n",
      "\n",
      "Saw 1145856 samples.\n",
      "Ran 14953.0508881 seconds. (This epoch: 92.1769798265 samples / second)\n",
      "Train accuracy: 0.55\n",
      "Test accuracy: 0.65625\n",
      "\n",
      "Saw 1152256 samples.\n",
      "Ran 15022.2529702 seconds. (This epoch: 92.1871367448 samples / second)\n",
      "Train accuracy: 0.54125\n",
      "Test accuracy: 0.625\n",
      "\n",
      "Saw 1158656 samples.\n",
      "Ran 15092.0137322 seconds. (This epoch: 92.1727185472 samples / second)\n",
      "Train accuracy: 0.54515625\n",
      "Test accuracy: 0.59375\n",
      "\n",
      "Saw 1165056 samples.\n",
      "Ran 15161.4126761 seconds. (This epoch: 92.1742081157 samples / second)\n",
      "Train accuracy: 0.54265625\n",
      "Test accuracy: 0.65625\n",
      "\n",
      "Saw 1171456 samples.\n",
      "Ran 15230.9268951 seconds. (This epoch: 92.1709717249 samples / second)\n",
      "Train accuracy: 0.5534375\n",
      "Test accuracy: 0.671875\n",
      "\n",
      "Saw 1177856 samples.\n",
      "Ran 15300.4909041 seconds. (This epoch: 92.1659827168 samples / second)\n",
      "Train accuracy: 0.54484375\n",
      "Test accuracy: 0.671875\n",
      "\n",
      "Saw 1184256 samples.\n",
      "Ran 15369.0711551 seconds. (This epoch: 92.1985860886 samples / second)\n",
      "Train accuracy: 0.54921875\n",
      "Test accuracy: 0.640625\n",
      "\n",
      "Saw 1190656 samples.\n",
      "Ran 15438.7377892 seconds. (This epoch: 92.1893196508 samples / second)\n",
      "Train accuracy: 0.548125\n",
      "Test accuracy: 0.640625\n",
      "\n",
      "Saw 1197056 samples.\n",
      "Ran 15507.7026041 seconds. (This epoch: 92.2057396073 samples / second)\n",
      "Train accuracy: 0.5521875\n",
      "Test accuracy: 0.640625\n",
      "\n",
      "Saw 1203456 samples.\n",
      "Ran 15577.048969 seconds. (This epoch: 92.2079635121 samples / second)\n",
      "Train accuracy: 0.5503125\n",
      "Test accuracy: 0.671875\n",
      "\n",
      "Saw 1209856 samples.\n",
      "Ran 15646.002697 seconds. (This epoch: 92.2234473053 samples / second)\n",
      "Train accuracy: 0.55078125\n",
      "Test accuracy: 0.65625\n",
      "\n",
      "Saw 1216256 samples.\n",
      "Ran 15715.6479821 seconds. (This epoch: 92.2151902446 samples / second)\n",
      "Train accuracy: 0.56203125\n",
      "Test accuracy: 0.609375\n",
      "\n",
      "Saw 1222656 samples.\n",
      "Ran 15785.7784171 seconds. (This epoch: 92.1916240963 samples / second)\n",
      "Train accuracy: 0.54984375\n",
      "Test accuracy: 0.625\n",
      "\n",
      "Saw 1229056 samples.\n",
      "Ran 15855.687391 seconds. (This epoch: 92.1761889984 samples / second)\n",
      "Train accuracy: 0.554375\n",
      "Test accuracy: 0.609375\n",
      "\n",
      "Saw 1235456 samples.\n",
      "Ran 15925.4165871 seconds. (This epoch: 92.1670241427 samples / second)\n",
      "Train accuracy: 0.56375\n",
      "Test accuracy: 0.640625\n",
      "\n",
      "Saw 1241856 samples.\n",
      "Ran 15994.375422 seconds. (This epoch: 92.1815123991 samples / second)\n",
      "Train accuracy: 0.539375\n",
      "Test accuracy: 0.671875\n",
      "\n",
      "Saw 1248256 samples.\n",
      "Ran 16063.9001882 seconds. (This epoch: 92.1786650637 samples / second)\n",
      "Train accuracy: 0.55671875\n",
      "Test accuracy: 0.6875\n",
      "\n",
      "Saw 1254656 samples.\n",
      "Ran 16133.443809 seconds. (This epoch: 92.1753976392 samples / second)\n",
      "Train accuracy: 0.549375\n",
      "Test accuracy: 0.671875\n",
      "\n",
      "Saw 1261056 samples.\n",
      "Ran 16202.4084411 seconds. (This epoch: 92.188621692 samples / second)\n",
      "Train accuracy: 0.5446875\n",
      "Test accuracy: 0.65625\n",
      "\n",
      "Saw 1267456 samples.\n",
      "Ran 16271.725456 seconds. (This epoch: 92.1915500644 samples / second)\n",
      "Train accuracy: 0.550625\n",
      "Test accuracy: 0.65625\n",
      "\n",
      "Saw 1273856 samples.\n",
      "Ran 16340.743715 seconds. (This epoch: 92.2024556349 samples / second)\n",
      "Train accuracy: 0.54546875\n",
      "Test accuracy: 0.640625\n",
      "\n",
      "Saw 1280256 samples.\n",
      "Ran 16410.3916202 seconds. (This epoch: 92.1962025599 samples / second)\n",
      "Train accuracy: 0.54171875\n",
      "Test accuracy: 0.6875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mu_acc = 0.0\n",
    "e_start = time.time()\n",
    "start_samples = seen_samples\n",
    "output_every_n = 100\n",
    "\n",
    "for i in xrange(n_batches_per_epoch):\n",
    "    x,y = get_batch(batch_size)\n",
    "    seen_samples += batch_size\n",
    "    _,acc =  model.train_on_batch(x, y)\n",
    "    mu_acc += acc\n",
    "    if i % output_every_n == 0 and i > 0:\n",
    "        print \"Saw \" + str(seen_samples) + \" samples.\"\n",
    "        t = time.time()\n",
    "        print \"Ran \" + str(t-start) + \" seconds. (This epoch: \" +\\\n",
    "            str((seen_samples-start_samples)*1./(t-e_start)) + \" samples / second)\"\n",
    "        print \"Train accuracy: \" + str(1./float(output_every_n)*mu_acc)\n",
    "        mu_acc = 0.0\n",
    "        _,acc = model.test_on_batch(valid_x, valid_y)\n",
    "        print \"Test accuracy: \" + str(acc)\n",
    "        print\n",
    "\n",
    "model.save(\"charlevel_b3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tThough Bill conceded that FBI Director Comey's decision to revive Hillary's email scandal created a problem for her campaign, he believed the issue had little impact on the outcome because it had already been baked into the decisions of most voters. But he does a prepare of the body sense to be the result of the horrorism and the based to you be the subject to plated his important career of the companion of self-pension, to see the line, and that the light of the paper of the content and \"The statement for the Wall Street Journal of the length of the content to a sensite than the securate on the hortologue and the time of the state billing of the content to the anti-News Starr see in decade with a second Internet statement of the more one f\n",
      "\tThough Bill conceded that FBI Director Comey's decision to revive Hillary's email scandal created a problem for her campaign, he believed the issue had little impact on the outcome because it had already been baked into the decisions of most voters. The most of the how seem to see a decontracted to the statement. For a service is not one of the adian to the about the story before the bovernment of the ground of the reason, and the media committed to see the tales of the content and that because the parentary trained, and the time and the paper of the end of the statement of the anti-- and the time than their about the more on the policy of the media last common and a political campaign in the action of the paper for a few and bottony of the\n",
      "\tThough Bill conceded that FBI Director Comey's decision to revive Hillary's email scandal created a problem for her campaign, he believed the issue had little impact on the outcome because it had already been baked into the decisions of most voters. I seen to burden committed to be a final and serves than the bin than in the content and she seemed a serve for the billing recent time and the posed of a few few winders.\" parents, and continued to expect at the past of the confessional and self-include politics of the security end of the New York Communist standards. The column is not to the confeting of the Columbian and in the Post . But it was a comen contribution of the sense of the companies to that the condection has a second research to\n",
      "\tThough Bill conceded that FBI Director Comey's decision to revive Hillary's email scandal created a problem for her campaign, he believed the issue had little impact on the outcome because it had already been baked into the decisions of most voters. So comes to course the particulary hard to end in the Secret years. But a handle and the terroric and companing television of the market to content of the bad flom with the Senate. I have a poenting and the paper of the reversion, in the committed to offen to a more and press the string and content of the recent political terms big and employees and sees to come to the inferfiction between the might alone and the personal and devined than their companies is been to the first strategic and consen\n",
      "\tThough Bill conceded that FBI Director Comey's decision to revive Hillary's email scandal created a problem for her campaign, he believed the issue had little impact on the outcome because it had already been baked into the decisions of most voters. Are stated the paper by decades. It has a seen at all the responsibility of the team but the securated term seems to the broken and one of the term than the media care of the content for the top better in the paper of the end of subject. It states, the declare for the about his parent of the statement in the statement of the paper of the billing to committed to take to the an and an after the party in the particular case of the anticopers. But he would Hillary because self-personal national seco\n"
     ]
    }
   ],
   "source": [
    "text_len = 500\n",
    "n_samples = 5\n",
    "seed_string = \"\\tThough Bill conceded that FBI Director Comey's decision to revive Hillary's email scandal created a problem for her campaign, he believed the issue had little impact on the outcome because it had already been baked into the decisions of most voters. \"\n",
    "\n",
    "def tochar_prob(output):\n",
    "    summed = []\n",
    "    _sum = 0.0\n",
    "    output = output[0]\n",
    "    output = output**2\n",
    "    output /= sum(output)\n",
    "    for i in xrange(output.shape[0]):\n",
    "        _sum += output[i]\n",
    "        summed.append(_sum)\n",
    "    choice = random.random()\n",
    "    i = bisect.bisect(summed, choice)\n",
    "    return index_to_char[i]\n",
    "        \n",
    "def generate(length, seed='\\t', model=model):\n",
    "    seq = np.zeros((1, sample_len))\n",
    "    padding_len = sample_len - len(seed)\n",
    "    if padding_len < 1:\n",
    "        padding_len = 0\n",
    "    for i in xrange(padding_len):\n",
    "        seq[0,i] = 0\n",
    "    if len(seed) > sample_len:\n",
    "        seed = seed[len(seed)-sample_len:]\n",
    "    for i in xrange(len(seed)):\n",
    "        seq[0,padding_len+i] = char_to_index[seed[i]]\n",
    "        \n",
    "    string = list(seed_string)\n",
    "    for i in xrange(length):\n",
    "        c = tochar_prob(model.predict(seq))\n",
    "        string.append(c)\n",
    "        if c == '\\n':\n",
    "            break\n",
    "        seq = np.roll(seq, -1, axis=1)\n",
    "        seq[0,-1] = char_to_index[c]\n",
    "    return ''.join(string)\n",
    "\n",
    "for i in xrange(n_samples):\n",
    "    print generate(text_len, seed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
