{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 950 (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import collections\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4531\n",
      "27629896\n"
     ]
    }
   ],
   "source": [
    "def remove_hidden(l):\n",
    "    return filter(lambda s: not s[0] == '.', l)\n",
    "\n",
    "d = \"//home//xgamer//OANC-GrAF//data//written_1//journal//slate\"\n",
    "\n",
    "def get_files(d):\n",
    "    files = os.listdir(d)\n",
    "    files = remove_hidden(files)\n",
    "    return map(lambda f: d + \"//\" + f, files)\n",
    "\n",
    "dirs = get_files(d)\n",
    "files = map(get_files, dirs)\n",
    "files = [f for l in files for f in l]\n",
    "files = filter(lambda f: f[-3:] == 'txt', files)\n",
    "\n",
    "print len(files)\n",
    "\n",
    "texts = []\n",
    "for f in files:\n",
    "    f = open(f)\n",
    "    texts.append('\\n'.join(f.readlines()[7:]))\n",
    "    f.close()\n",
    "\n",
    "print sum([len(text) for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25425786\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = text.strip()\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('--', ' - ')\n",
    "    text = text.replace('\\t', ' ')\n",
    "    text = re.sub(r'\\ \\ +', r' ', text)\n",
    "    text = filter(lambda char: char in string.printable, text)\n",
    "    return text\n",
    "\n",
    "texts = map(clean_text, texts)\n",
    "print sum([len(text) for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trustbusters Have Job Security The Dec. 14 edition of \"Today's Papers\" notes a Washington Post report that David Boies, the lead Justice Department attorney in the Microsoft case, has lowered the hourly fee that he is charging the government. The column asks whether this is legal, if Boies' motive was to keep his share of the work. The answer can be found in the definitive rhyming opus on antitrust law, R.W. Grant's Tom Smith and His Incredible Bread Machine : You're gouging on your prices if You charge more than the rest. But it's unfair competition If you think you can charge less! A second point that we would make To help avoid confusion Don't try to charge the same amount! That would be collusion! In short, Boies' reduction of his fee constitutes unfair competition. Of course, if he'd left his fee unchanged, that would be collusion, though in this case he'd be colluding with himself and would eventually go blind. How's that for legal clarity? - Sam Kazman Washington Bork and Mindy Are there two Robert Borks, as Michael Kinsley writes in \"\"? But not just on antitrust. We have two Borks for probably any subject. Give the man a retainer or the proper ideological cause and he readily will tailor his views to the needs of the moment. I interviewed Bork several years ago for my book The Wars of Watergate . His role in the Watergate affair has, in all fairness, been badly distorted. Never mind. In our conversation, he spoke very forcefully against the special prosecutor (now independent counsel) statute. \"You cannot bag a case in the Justice Department,\" he told me. \"Too many lawyers, who like to talk to too many reporters.\" He was absolutely right, of course. Fast forward to 1994 and beyond. An independent counsel to investigate President Clinton? Of course. And \"Judge\" Kenneth Starr to conduct the investigation? Of course, said Bork, who appears as a regular cast member in those situation comedies that pass as \"talk shows\" every night, vigorously extolling the virtues and honesty of \"Judge\" Starr. Kinsley comes close to the real reason for rejecting Bork for a seat on the Supreme Court. The man has the intellectual honesty of a hired gun. Which he has truly become. - Stanley I. Kutler Fox Professor of American Institutions University of Wisconsin Madison, Wis. First, We Kill All the Lawyers I'm sure Michael Kinsley's \"Book Bork, Browser Bork\" is right to say that Robert Bork's current posture on the Microsoft antitrust case represents a departure from his 20-year-old book on antitrust law. But since when is a lawyer expected to actually possess the views he espouses on behalf of his clients? If the Kinsley Doctrine is that a client can only select a lawyer who honestly believes in the legal arguments of the client, then Bill Clinton wouldn't have any lawyers. - Robert Little Memphis, Tenn. Perjury Is Bad, Smearing Is Worse Just a quick point on David Plotz's \"Dispatch \" from the Dec. 9 House Judiciary Committee hearing. Plotz writes, \"Yesterday I called Lindsey Graham, R-S.C., 'admirable.' I apologize. ... This afternoon, Graham reveals himself, and he does it in such a calculating way that I wonder whether everything he has done till now has been pure performance. As the final speaker on the final day of hearings, Graham unleashes a 15 minute harangue about Clintonian evil. Clinton's true crime is not perjury or adultery, Graham shouts, it's that he planned to destroy Monica.\" Isn't the most reprehensible aspect of Clinton's conduct from a moral point of view the fact that he either orchestrated or knowingly permitted the resources of his position and office to be used in an attempt to destroy the reputations of those who have accused him of misdeeds? The story of the sexual activity is disturbing, given the power imbalances between the participants, but the story is a tawdry one, and most well-mannered people would just as soon not have to hear about it, especially since the \"victim\" is not making any complaint. The lying can be viewed as a natural human failing, which most people, it appears, are ready to forgive. Lying under oath is a more serious matter, but it is more serious for institutional reasons rather than purely moral ones. As the head of state and a living symbol of a system, which, in the name of justice, imposes laws upon and claims the right to exercise coercive power over all Americans, the president has a special duty - higher than that of an ordinary citizen - to abide by the rules that the system imposes. One of the most important rules for the whole justice system is the penalty against perjury. It is only right that Congress should take that issue seriously. But from a purely moral point of view, is it not utterly despicable for the president of the United States to use the power of his office to destroy the reputation of a person for the sole purpose of ensuring that that person will not be believed when she tells the truth? Such conduct may not be a \"high crime or misdemeanor.\" It may not even be illegal. But it is surely a moral abuse of the powers of the presidency that should not go unnoticed. - Kenneth J. Tyler Vancouver, British Columbia Jocks of the World, Unite! You Have Nothing To Lose but Your Scholarships! Jim Naughton's \"\" has missed the forest for the trees. He complains that a few powerful schools are aligning themselves to take a larger slice of the revenues generated by big-time college athletics and bemoans the small colleges whose athletic programs will be destroyed by this. What Naughton has missed is that the entire NCAA system is corrupt, making millions of dollars off student athletes who can't even accept plane fare from alumni to visit family. That's the real travesty of college sports. Arguing which schools should keep the huge revenues generated by athletes really misses the point. - Anthony Lapadula Redmond, Wash. Address your e-mail to the editors to letters@slate.com. You must include your address and daytime phone number (for confirmation only).\n"
     ]
    }
   ],
   "source": [
    "print texts[545]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '}', '~', '\\t', '\\n']\n",
      "{0: ' ', 1: '!', 2: '\"', 3: '#', 4: '$', 5: '%', 6: '&', 7: \"'\", 8: '(', 9: ')', 10: '*', 11: '+', 12: ',', 13: '-', 14: '.', 15: '/', 16: '0', 17: '1', 18: '2', 19: '3', 20: '4', 21: '5', 22: '6', 23: '7', 24: '8', 25: '9', 26: ':', 27: ';', 28: '<', 29: '=', 30: '>', 31: '?', 32: '@', 33: 'A', 34: 'B', 35: 'C', 36: 'D', 37: 'E', 38: 'F', 39: 'G', 40: 'H', 41: 'I', 42: 'J', 43: 'K', 44: 'L', 45: 'M', 46: 'N', 47: 'O', 48: 'P', 49: 'Q', 50: 'R', 51: 'S', 52: 'T', 53: 'U', 54: 'V', 55: 'W', 56: 'X', 57: 'Y', 58: 'Z', 59: '[', 60: '\\\\', 61: ']', 62: '^', 63: '_', 64: '`', 65: 'a', 66: 'b', 67: 'c', 68: 'd', 69: 'e', 70: 'f', 71: 'g', 72: 'h', 73: 'i', 74: 'j', 75: 'k', 76: 'l', 77: 'm', 78: 'n', 79: 'o', 80: 'p', 81: 'q', 82: 'r', 83: 's', 84: 't', 85: 'u', 86: 'v', 87: 'w', 88: 'x', 89: 'y', 90: 'z', 91: '{', 92: '}', 93: '~', 94: '\\t', 95: '\\n'}\n",
      "{' ': 0, '$': 4, '(': 8, ',': 12, '0': 16, '4': 20, '8': 24, '<': 28, '@': 32, 'D': 36, 'H': 40, 'L': 44, 'P': 48, 'T': 52, 'X': 56, '\\\\': 60, '`': 64, 'd': 68, 'h': 72, 'l': 76, 'p': 80, 't': 84, 'x': 88, '#': 3, \"'\": 7, '+': 11, '/': 15, '3': 19, '7': 23, ';': 27, '?': 31, 'C': 35, 'G': 39, 'K': 43, 'O': 47, 'S': 51, 'W': 55, '[': 59, '_': 63, 'c': 67, 'g': 71, 'k': 75, 'o': 79, 's': 83, 'w': 87, '{': 91, '\\n': 95, '\"': 2, '&': 6, '*': 10, '.': 14, '2': 18, '6': 22, ':': 26, '>': 30, 'B': 34, 'F': 38, 'J': 42, 'N': 46, 'R': 50, 'V': 54, 'Z': 58, '^': 62, 'b': 66, 'f': 70, 'j': 74, 'n': 78, 'r': 82, 'v': 86, 'z': 90, '~': 93, '\\t': 94, '!': 1, '%': 5, ')': 9, '-': 13, '1': 17, '5': 21, '9': 25, '=': 29, 'A': 33, 'E': 37, 'I': 41, 'M': 45, 'Q': 49, 'U': 53, 'Y': 57, ']': 61, 'a': 65, 'e': 69, 'i': 73, 'm': 77, 'q': 81, 'u': 85, 'y': 89, '}': 92}\n"
     ]
    }
   ],
   "source": [
    "alphabet = collections.defaultdict(bool)\n",
    "\n",
    "for text in texts:\n",
    "    for char in text:\n",
    "        alphabet[char] = True\n",
    "\n",
    "alphabet = [char for char in alphabet if alphabet[char] == True]\n",
    "alphabet.sort()\n",
    "\n",
    "# Add a start of sequence token \\t\n",
    "alphabet.append('\\t')\n",
    "# Add an end of sequence token \\n\n",
    "alphabet.append('\\n')\n",
    "\n",
    "texts = map(lambda text: '\\t' + text + '\\n', texts)\n",
    "print alphabet\n",
    "\n",
    "char_to_index = {}\n",
    "index_to_char = {}\n",
    "for i in xrange(len(alphabet)):\n",
    "    index_to_char[i] = alphabet[i]\n",
    "    char_to_index[alphabet[i]] = i\n",
    "print index_to_char\n",
    "print char_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "licy of trade-plus-scolding. While demanding boldness abroad, they have opposed military action in Kosovo, Iraq, Sudan, and Afghanistan. And while falling back on Cold War rhetoric, they ignore Russia'\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "licy of trade-plus-scolding. While demanding boldness abroad, they have opposed military action in Kosovo, Iraq, Sudan, and Afghanistan. And while falling back on Cold War rhetoric, they ignore Russia\n",
      "200 200\n"
     ]
    }
   ],
   "source": [
    "text_seq = ''.join(texts)\n",
    "sample_len = 200\n",
    "\n",
    "def sample(text, length=sample_len + 1):\n",
    "    i = random.randint(0, len(text) - length - 1)\n",
    "    return text[i:i+length]\n",
    "\n",
    "def toseqs(string, alphabet=alphabet):\n",
    "    assert len(string) > 1\n",
    "    n = len(string) - 1\n",
    "    data = np.zeros((n, len(alphabet)), dtype='uint8')\n",
    "    label = np.zeros(len(alphabet), dtype='uint8')\n",
    "    for i in xrange(n):\n",
    "        cur = string[i]\n",
    "        nxt = string[i+1]\n",
    "        data[i][char_to_index[cur]] = 1\n",
    "    label[char_to_index[nxt]] = 1\n",
    "    return data, label\n",
    "\n",
    "s = sample(text_seq)\n",
    "print s\n",
    "x,y = toseqs(s)\n",
    "print x[0]\n",
    "print y\n",
    "\n",
    "def tostring(seq, alphabet=alphabet):\n",
    "    string = []\n",
    "    for i in xrange(seq.shape[0]):\n",
    "        string.append(index_to_char[np.argmax(seq[i])])\n",
    "    return ''.join(string)\n",
    "\n",
    "print tostring(x)\n",
    "print len(x), len(tostring(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "NN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 96\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "print sample_len, len(alphabet)\n",
    "model.add(Dense(30, input_shape=(None, len(alphabet))))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(len(alphabet)))\n",
    "model.add(Activation('softmax'))\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#rmsprop = RMSprop()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(size, text=text_seq):\n",
    "    xs = np.zeros((size, sample_len, len(alphabet)), dtype='uint8')\n",
    "    ys = np.zeros((size, len(alphabet)), dtype='uint8')\n",
    "    for i in xrange(size):\n",
    "        s = sample(text)\n",
    "        x,y = toseqs(s)\n",
    "        xs[i] = x\n",
    "        ys[i] = y\n",
    "    return xs, ys\n",
    "\n",
    "valid_x, valid_y = get_batch(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.4942578125\n",
      "Test accuracy: 0.505859375\n",
      "\n",
      "Train accuracy: 0.4918359375\n",
      "Test accuracy: 0.509765625\n",
      "\n",
      "Train accuracy: 0.49271484375\n",
      "Test accuracy: 0.51953125\n",
      "\n",
      "Train accuracy: 0.4941796875\n",
      "Test accuracy: 0.517578125\n",
      "\n",
      "Train accuracy: 0.4869921875\n",
      "Test accuracy: 0.5234375\n",
      "\n",
      "Train accuracy: 0.4877734375\n",
      "Test accuracy: 0.505859375\n",
      "\n",
      "Train accuracy: 0.4902734375\n",
      "Test accuracy: 0.513671875\n",
      "\n",
      "Train accuracy: 0.4925390625\n",
      "Test accuracy: 0.50390625\n",
      "\n",
      "Train accuracy: 0.493984375\n",
      "Test accuracy: 0.505859375\n",
      "\n",
      "Train accuracy: 0.4923046875\n",
      "Test accuracy: 0.513671875\n",
      "\n",
      "Train accuracy: 0.491015625\n",
      "Test accuracy: 0.517578125\n",
      "\n",
      "Train accuracy: 0.4881640625\n",
      "Test accuracy: 0.51171875\n",
      "\n",
      "Train accuracy: 0.486484375\n",
      "Test accuracy: 0.509765625\n",
      "\n",
      "Train accuracy: 0.492109375\n",
      "Test accuracy: 0.513671875\n",
      "\n",
      "Train accuracy: 0.49416015625\n",
      "Test accuracy: 0.509765625\n",
      "\n",
      "Train accuracy: 0.49177734375\n",
      "Test accuracy: 0.513671875\n",
      "\n",
      "Train accuracy: 0.490625\n",
      "Test accuracy: 0.51171875\n",
      "\n",
      "Train accuracy: 0.4876171875\n",
      "Test accuracy: 0.51953125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mu_acc = 0.0\n",
    "    \n",
    "for i in xrange(10001):\n",
    "    x,y = get_batch(512)\n",
    "    _,acc =  model.train_on_batch(x, y)\n",
    "    mu_acc += acc\n",
    "    if i % 100 == 0 and i > 0:\n",
    "        print \"Train accuracy: \" + str(0.01*mu_acc)\n",
    "        mu_acc = 0.0\n",
    "        _,acc = model.test_on_batch(valid_x, valid_y)\n",
    "        print \"Test accuracy: \" + str(acc)\n",
    "        print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRussia is starting to withdraw forces from Syria and its aircraft carrier group will be the first to leave, the Russian armed forces chief says. \tThe sent the sent the sent the sent the sent the sent the sent the sent the sent the sent the sent \n"
     ]
    }
   ],
   "source": [
    "def generate(length, seed='\\t', model=model):\n",
    "    seq = np.zeros((1, length + len(seed) + 1, len(alphabet)))\n",
    "    for i in xrange(len(seed)):\n",
    "        seq[0][i][char_to_index[seed[i]]] = 1\n",
    "    string = []\n",
    "    for i in xrange(length):\n",
    "        c = model.predict(seq[:,:len(seed)+i+1,:])\n",
    "        c = tostring(c)\n",
    "        string.append(c)\n",
    "        seq[0][len(seed)+i+1][char_to_index[c]] = 1\n",
    "    return tostring(seq[0])\n",
    "\n",
    "print generate(100, \"\\tRussia is starting to withdraw forces from Syria and its aircraft carrier group will be the first to leave, the Russian armed forces chief says.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
